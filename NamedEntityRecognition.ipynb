{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "    Sentence #           Word  POS    Tag\n0  Sentence: 1      Thousands  NNS      O\n1  Sentence: 1             of   IN      O\n2  Sentence: 1  demonstrators  NNS      O\n3  Sentence: 1           have  VBP      O\n4  Sentence: 1        marched  VBN      O\n5  Sentence: 1        through   IN      O\n6  Sentence: 1         London  NNP  B-geo",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 1</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 1</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 1</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sentence: 1</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sentence: 1</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"venv/ner_dataset.csv\", encoding=\"latin1\")\n",
    "df = df.fillna(method=\"ffill\")\n",
    "df.head(7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "    Sentence #           Word  POS  Tag\n0  Sentence: 1      Thousands  NNS    0\n1  Sentence: 1             of   IN    0\n2  Sentence: 1  demonstrators  NNS    0\n3  Sentence: 1           have  VBP    0\n4  Sentence: 1        marched  VBN    0\n5  Sentence: 1        through   IN    0\n6  Sentence: 1         London  NNP    1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 1</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 1</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 1</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sentence: 1</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sentence: 1</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace tag by integers\n",
    "modes_tag = df.Tag.unique()\n",
    "n_tags = len(modes_tag)\n",
    "tag2idx={t:i for i,t in enumerate(modes_tag)}\n",
    "df['Tag'] = df.Tag.replace(tag2idx)\n",
    "df.head(7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048575, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                Word  \\\n0  [Thousands, of, demonstrators, have, marched, ...   \n1  [Iranian, officials, say, they, expect, to, ge...   \n2  [Helicopter, gunships, Saturday, pounded, mili...   \n3  [They, left, after, a, tense, hour-long, stand...   \n4  [U.N., relief, coordinator, Jan, Egeland, said...   \n5  [Mr., Egeland, said, the, latest, figures, sho...   \n6  [He, said, last, week, 's, tsunami, and, the, ...   \n\n                                                 Tag  \n0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n1  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, ...  \n3                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n4  [1, 0, 0, 3, 10, 0, 7, 0, 1, 0, 2, 0, 2, 0, 0,...  \n5  [3, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n      <td>[0, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[They, left, after, a, tense, hour-long, stand...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n      <td>[1, 0, 0, 3, 10, 0, 7, 0, 1, 0, 2, 0, 2, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[Mr., Egeland, said, the, latest, figures, sho...</td>\n      <td>[3, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[He, said, last, week, 's, tsunami, and, the, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.drop(['POS'], axis=1)\n",
    "df = df.groupby('Sentence #').agg(list)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum size of a sentence : 104\n"
     ]
    }
   ],
   "source": [
    "len_max = max(df.Word.apply(len))\n",
    "print(\"Maximum size of a sentence :\", len_max)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_text_train, X_text_test, y_train, y_test = train_test_split(df.Word, df.Tag, test_size=0.2, random_state=1234)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "8872     [0, 0, 0, 0, 0, 7, 0, 1, 0, 3, 0, 0, 0, 0, 0, ...\n36510    [0, 0, 0, 7, 0, 0, 0, 1, 4, 0, 1, 0, 3, 10, 0,...\n15093    [0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, ...\n26251    [5, 0, 5, 6, 0, 0, 0, 5, 0, 0, 0, 3, 5, 0, 0, ...\n6517     [0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...\n                               ...                        \n26232              [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0]\n9251     [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n3302     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n24304    [3, 10, 0, 0, 1, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0,...\n46087    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...\nName: Tag, Length: 9592, dtype: object"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Définition du tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "# Mettre à jour le dictionnaire du tokenizer\n",
    "tokenizer.fit_on_texts(X_text_train)\n",
    "# Définition des dictionnaires\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = tokenizer.index_word\n",
    "vocab_size = tokenizer.num_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_text_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_text_test)\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=len_max, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=len_max, padding='post')\n",
    "y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train, maxlen=len_max, padding='post', value=n_tags)\n",
    "y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test, maxlen=len_max, padding='post', value=n_tags)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   4   80    9 1125    3 2107    4  135 2929    9  126    7 2074 8168\n",
      "  1024    8    7 3801 8168 1024    8 1742  191    4    1  574    2    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [1633  619   30 1536  476    6 1093  226    5  792    4   37 3468 1353\n",
      "    14   15 6790    1   76    9 2345   21 1996    2    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [ 212  123  152    1 2664    6    1 8169    8  359  191  138   16    1\n",
      "  4721  318    2    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [  46 4722   20  723  397    6  337   12 1696    2    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [ 559    1  296    8   17  503   35  865  342  629   32  626   12  296\n",
      "     2    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]] [[ 0  7  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  5  0  0  0  0  0  5\n",
      "   6  0  0  0  0  0  0  0  0 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17]\n",
      " [ 0  3  0  0  0  0  0  0  0  0 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17]\n",
      " [ 3  0  0  0  0  0  2  3 10 10  0  0  0  0  0  0  0 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      "  17 17 17 17 17 17 17 17]]\n",
      "Shape of sentence X : (38367, 104)\n",
      "Shape of tags y : (38367, 104)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5,:], y_train[:5,:])\n",
    "print('Shape of sentence X :', X_train.shape)\n",
    "print('Shape of tags y :', y_train.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 10000)       100000000 \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 512)         15756288  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 18)          9234      \n",
      "=================================================================\n",
      "Total params: 115,765,522\n",
      "Trainable params: 115,765,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN, GRUCell, Conv2D, Embedding, Bidirectional, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vocab_size))\n",
    "model.add(Bidirectional(RNN(GRUCell(256, recurrent_initializer='glorot_uniform'),\n",
    "                                return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "# la sortie a n_tags+1 units, c'est à dire le nombre de tags possibles plus la classe utililisée pour égalisée\n",
    "# la taille des data (qui ne sera pas prise en compte dans l'entraînement grâce à la fonction de coût customisée)\n",
    "model.add(Dense(n_tags+1, activation='softmax'))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # Mask => vaudra 0 lorsque y vaut n_tags, c'est à dire la valeur avec laquelle on a compléter le tableau y_train\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, n_tags))\n",
    "    # Pour respecter le type de y\n",
    "    mask = tf.cast(mask, dtype=pred.dtype)\n",
    "    # fonction de perte\n",
    "    loss_ = loss_object(real, pred)\n",
    "    # Apply mask on loss function\n",
    "    loss_ *= mask\n",
    "    # on renvoit la moyenne calculée en dehors de mask = 0, valeur que l'on ne veut pas prendre en compte ds le calcul\n",
    "    return tf.reduce_mean(loss_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "model.compile(loss=loss_function, optimizer='adam')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=16, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prediction sur les 10 premières phrases\n",
    "y_prob = model.predict(X_test[:10])\n",
    "y_pred = y_prob.argmax(axis=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def target2text(X_int, y_pred):\n",
    "    X = []\n",
    "    for i in range(len(y_pred)):\n",
    "        text=''\n",
    "        for j in np.flip(np.arange(len(y_pred[0]))):\n",
    "            if y_pred[i, j]==1 :\n",
    "                text = ' ' + text\n",
    "            text = idx2word[X_int[i, j]] + text\n",
    "        X.append(text)\n",
    "    return X\n",
    "\n",
    "print('Prediction :')\n",
    "target2text(X_test[:len(y_pred)], y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"OK\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}